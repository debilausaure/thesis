\chapter{État de l'art (20-30 pages)}

	Ce chapitre a pour intention de définir et préciser les différentes notions nécessaires à la lecture des travaux de thèses, ainsi que de définir le contexte scientifique du travail. Il portera, dans une première section, sur les détails des différents transferts de flot d'exécution dans les systèmes modernes, ainsi que les changements d'états inhérents à ces transferts de flot d'exécution. Cette section abordera ensuite les problèmes de sécurité liés au transfert de flot d'exécution, ainsi que les techniques de mitigation de ces problèmes. Cette section terminera sur les problématiques temps réel touchant au transfert de flot d'exécution.
	La seconde section de ce chapitre fera un état des lieux de la preuve de programme. Elle commencera par discuter de ce qu'est une preuve et de leur vérificaton automatique, ainsi que des stratégies de conduite de preuve. Cette section continuera sur la preuve de programme, en particulier comment raisonner sur un programme impératif. Elle abordera aussi les notions de représentation du langage. Enfin, elle terminera sur les exemples de systèmes vérifiés formellement.

	\section{Transfert de flôt d'exécution}

		Cette section va détailler les différents transferts de flot d'exécution mis à disposition dans les cpus modernes.
		Dans cette section, nous détaillerons les transferts de flot d'exécution qui impliquent une reconfiguration explicite de l'état de la machine ayant un impact sur les droits d'accès aux ressources. Les appels d'une fonction d'un programme vers une autre fonction ne seront pas considérés dans cette section, même s'ils pourraient être considérés comme un transfert de flôt d'exécution. 


		\subsection{Hardware}

			\subsubsection{Appels explicites}
			Les transferts les plus courants sont les transferts de flot d'exécution explicites, c'est-à-dire dont la cible est explicitement fournie lors de l’appel, ou clairement établie dans la documentation.

Par exemple, dans Linux, un processus peut demander l’ouverture d’un fichier avec l’appel système open(). Cet appel transfère le flot d’exécution d’un processus non privilégié vers le noyau Linux disposant du plus haut niveau de privilèges. Les fonctions appelables par des transferts explicites servent d’interface entre des logiciels disposant de droits distincts.

Ce type de transfert de flôt d'exécution, d'apparence assez anodine, est pourtant l'objet d'attaques multiples, dont le but est de faire dévier l'exécution (de préférence en mode privilégié) vers du code choisi par l'attaquant. Pour y arriver, un attaquant doit exploiter une vulnérabilité dans une portion de code, qui lui donnera le contrôle d'une zone de mémoire d'intérêt (la pile, le tas, ou même le code). Une fois qu'il contrôle cette zone mémoire, il lui suffit d'écrire un \emph{shellcode}, et d'exploiter une vulnérabilité dans du code privilégié pour que l'exécution du \texttt{return} de la fonction compromise saute dans le shellcode. L'attaquant gagne à ce moment le contrôle de la machine.

Commence alors un jeu du chat et de la souris pour essayer de mitiger l'impact de ces vulnérabilités. Pour compliquer la vie de l'attaquant, et qu'il lui soit plus difficile d'exécuter son shellcode, de nombreuses stratégies ont été entreprises par les fabriquant de matériels ainsi que par les développeurs de systèmes d'exploitation. 

\paragraph{Canaries}
Une première statégie est l'ajout de \emph{canary} qui visent à détecter les corruptions mémoires. Les canaries sont des valeurs écrites dans la pile ou le tas et qui sont générées aléatoirement à chaque exécution. Lors de la sortie de la frame protégée par le canary, le code vérifie que la valeur du canary correspond bien à celle qui avait été écrite initialement ; si ce n'est pas le cas, c'est qu'une corruption mémoire a eu lieu et une faute est levée.

Une des techniques permettant de vaincre les canaries est de lire la valeur initiale du canary avant de corrompre la mémoire. En effet, la canary \textbf{reste la même pour l'intégralité de l'exécution}. Une fois cette valeur récupérée, il suffit de corrompre la mémoire en réécrivant cette valeur au bon endroit pour échapper à la détection. De plus, si l'exploitation de la vulnérabilité permet de corrompre la mémoire de manière fine, il suffit d'éviter d'écrire sur la canary.

\paragraph{Droits fins pour les zones mémoires}
Une autre stratégie a été de définir des droits fins concernant l'accès aux différentes zones mémoires de l'espace d'adressage des processus. Le mécanisme de mémoire virtuelle permet de définir des droits d'accès propres à chaque page mémoire configurée (lecture, écriture, éxecution, accessible en mode non priviligié). Par exemple, les pages mémoire contenant du code sont typiquement configurées pour des accès en lecture et exécution, alors que les pages contenant des données (pour la pile, le tas, les sections de données d'un binaire) sont configurées pour des accès en lecture/écriture.

Cette stratégie de défense empêche un attaquant d'exploiter une vulnérabilité pour écrire un shellcode code dans la mémoire si on considère que chaque page de mémoire est soit exécutable, soit accessible en écriture. Cependant, il existe des cas d'usage légitimes qui violent cette contrainte, par exemple lors de compilation à la volée (ou JIT, pour Just-In-Time). Fatalement, de tels logiciels sont devenus la cible privilégiée des attaquants, on pourra par exemple citer Webkit.% https://github.com/saelo/cve-2018-4233
Heureusement, il est peu probable que de tels logiciels aient besoin de s'exécuter en mode privilégié. 

Pour affaiblir ce vecteur d'attaque, cette stratégie de défense est renforcée par des mécanismes de sécurité supplémentaires tels que le \emph{Supervisor Mode Access Prevention} (SMAP) et le \emph{Supervisor Mode Execution Prevention} (SMEP). SMAP permet au processeur de lever une faute lorsque qu'il exécute du code privilégié et qu'il essaie d'accéder (en lecture ou en écriture) à des données présentes dans l'espace utilisateur. SMEP permet en complément de lever une faute lorsque le processeur essaie d'exécuter du code dans l'espace utilisateur alors qu'il se trouve dans un mode d'exécution privilégié.

Ces mécanismes permettent d'isoler le code privilégié de potentiels shellcodes écrit en espace utilisateur. Ainsi, pour compromettre intégralement un système, l'attaquant doit à présent exploiter une vulnérabilité dans le code privilégié, ayant à sa disposition des pages mémoire soit accessibles en écriture soit exécutables et qui, de surcrois, ne font pas partie de l'espace utilisateur.
Nait alors une nouvelle technique d'exploitation de vulnérabilité. 

\paragraph{Return Oriented Programming}
Le ROP (pour \emph{Return Oriented Programming}) consiste à attaquer du code vulnérable en n'utilisant que le code déjà accessible dans l'environnement d'origine, mais en exécutant des portions arbitraires de celui-ci. L'attaque consiste à repérer des \emph{gadgets} : de brèves portions de code ayant un effet spécifique sur la mémoire ou les registres, suivi d'une instruction \texttt{return}. Pour l'attaquant, il suffit de dévier le flot d'exécution sur l'un de ces gadgets et de manipuler la mémoire, de manière à ce que l'exécution du gadget entraine l'exécution du suivant. L'attaquant parvient au final à exécuter son shellcode constitué d'une succession de gadgets, contournant les mécanismes de sécurité mentionnés dans le paragraphe précédent.\\

Plusieurs contre-mesures ont émergé pour rendre plus difficile le ROP.

\paragraph{Address Space Layout Randomization}
L'ASLR (pour \emph{Address Space Layout Randomization}) rend imprédictible l'adresse des différentes zones de mémoire au sein d'un espace d'adressage virtuel. Les adresses du binaire, de la pile, du tas, des librairies, du noyau, etc. sont rendus aléatoires à chaque nouvelle exécution. L'ASLR est un de ce fait un frein considérable au développement d'un shellcode en ROP, puisqu'il est impossible de prédire où se situeront les gadgets lors de la prochaine exécution.

L'ASLR n'est cependant pas parfait. Les adresses des zones mémoire restantes peuvent être révélées par des pointeurs dans les zones mémoires controlées par l'attaquant, %https://google.github.io/security-research/pocs/linux/cve-2021-22555/writeup.html#bypassing-kaslrsmep and %https://google.github.io/security-research/pocs/linux/bleedingtooth/writeup.html#leaking-the-memory-layout
ou grâce à des attaques micro-architecturales % Prefetch Side-Channel Attacks: Bypassing SMAP and Kernel ASLR. In: CCS’16 (2016) && Practical Timing Side Channel Attacks against Kernel Space ASLR. In: S&P’13 (2013)

\paragraph{Vérification de l'intégrité du flôt d'exécution}

Une autre approche permettant de réduire la marge de manoeuvre de l'attaquant et de vérifier que le flot d'exécution est conforme à celui attendu. À chaque appel et à chaque retour de fonction, le processeur vérifie si la cible du saut est valide. Plusieurs implémentations existent, notamment au sein du matériel processeurs et des compilateurs. Windows, macOS, Android, iOS utilisent déjà une mécanisme de vérification du flot d'exécution.
% https://community.arm.com/arm-community-blogs/b/architectures-and-processors-blog/posts/armv8-1-m-pointer-authentication-and-branch-target-identification-extension
% https://www.intel.com/content/dam/develop/external/us/en/documents/catc17-introduction-intel-cet-844137.pdf
% https://clang.llvm.org/docs/ControlFlowIntegrity.html


\paragraph{eXecute Only Memory}
Le XOM (pour \emph{eXecute Only Memory}), est une fonctionnalité de certain processeurs permettant de déclencher une faute lorsque qu'un accès en lecture est fait sur les pages mémoires configurées comme étant exécutables. Avant cette fonctionnalité, aucune distinction n'était faite entre le processus de récupération des instructions par le processeur et la lecture de données par l'utilisateur. Cette fonctionnalité rend considérablement pour difficile la recherche de gadgets, puisqu'il est impossible pour l'attaquant de lire le code qu'il souhaite compromettre directement sur la cible.
On pourrait cependant argumenter que cette fonctionnalité relève de la sécurité par l'obscurité, et qu'elle n'est pas réellement efficace.

\paragraph{\blockquote{Mieux vaut prévenir que guérir}}

Ces contre-mesures, sans cesse contournées par de nouvelles méthodes d'attaque, supposent qu'il existera toujours des vulnérabilités dans le logiciel comme dans le matériel et tentent donc de limiter au maximum leur impact sur les systèmes affectés. Une toute autre classe de mesures essaie de régler le problème en s'attaquant à l'existence même des vulnérabilités, plutôt que d'essayer minimiser leurs conséquences.

On pourrait citer les méthodes d’analyse statique, les méthodes d’exécution symbolique, de fuzzing, et plus particulièrement le langage Rust conçu pour éradiquer ces vulnérabilités par conception. Par ailleurs, des travaux ont été entamés pour prouver formellement les fonctionnalités de Rust.


			\subsubsection{Fautes}

Les différentes formes de fautes logicielles constituent aussi une forme de transfert de flot d'exécution avec élévation de privilèges. Les logiciels sont susceptibles de déclencher des fautes logicielles de différentes façons, par exemple :
\begin{itemize}
  \item décodage impossible de la prochaine instruction ;
  \item demande d'exécution d'une instruction impossible (division par zéro...) ; 
  \item demande d'accès à une adresse mémoire protégée, résultat de l'activité d'une MMU ;  
  \item demande d'exécution d'une instruction privilégiée en mode non-privilégié.
\end{itemize}
Dans ces différentes situations il s'agit de transferts implicites depuis le logiciel en faute vers une fonction d'un logiciel en charge du traitement de cette faute. Les différentes fonctions de gestion des fautes sont généralement définies par des éléments de configuration du matériel, et, le plus souvent, par l'intermédiaire d'une table (ou vecteur) dont le nom change d'une architecture de microprocesseur à l'autre. Ce vecteur précise généralement le niveau d'élévation de privilèges associé à l'exécution de la fonction de traitement de la faute. Sur les architectures Intel cette table est appelée \emph{IDT} (pour \emph{Interrupt Descriptor Table}).

\subsubsection{Interruptions matérielles}
Les interruptions matérielles sont des transferts non explicites à priori non contrôlés par le code non privilégié. Elles sont déclenchées par le matériel, signalant un événement important à traiter, tel que l'arrivée d'un paquet réseau par exemple. Les fonctions de traitement des interruptions matérielles ainsi que leur niveau de privilèges sont aussi définis dans l'\emph{IDT}.

Puisque les fautes et interruptions déclenchent un changement de privilèges, elles sont un vecteur d'attaque supplémentaire d'intérêt pour un attaquant cherchant à s'octroyer de nouveaux droits. En effet, les mêmes types de failles peuvent résider dans les routines de gestion de ces portions de logiciel. De plus, les interruptions et fautes brisent le flot d'exécution et modifient potentiellement l'environnement d'exécution du code interrompu. Cela les rends d'autant plus susceptibles de contenir des vulnérabilités, qui tombent alors dans la catégorie des vulnérabilités de \emph{concurrence critique}.

Même en ayant pleinement conscience des différentes interactions et dépendances entre les différents composants d'un système, les vulnérabilités de concurrence critique sont \textbf{notoirement difficiles à cerner}, principalement à cause d'un phénomène d'explosion combinatoire. Il peut s'avérer difficile de détecter une telle vulnérabilité par les tests, puisqu'ils sont souvent effectués dans des environnement très controlés où les mêmes conditions d'exécution sont artificiellement répétées, occultant d'autres fils d'exécution possibles. Malgré cela, si le développeur parvient à exhiber un fil d'exécution contenant un comportement anormal, il peut alors être délicat de reproduire le fil d'exécution ayant conduit à ce comportement. En effet, le fil d'exécution peut etre le résultat de nombreuses interactions - parfois non-déterministes - du programme avec son environnement. De plus, attacher un debuggueur tel que \texttt{gdb} peut modifier subtilement ces interactions, de manière telle qu'il soit impossible d'exhiber à nouveau le comportement anormal : on parle alors d'Heisenbug. Pour illustrer la difficulté à cerner cette catégorie de bugs, on pourrait citer un problème d'incohérence de cache dans le noyau de système d'exploitation de la Nintendo Switch après une interruption matérielle ayant mené à un changement de coeur. Les effets de ce bug avaient été observés dès la sortie de la console ; il n'a cependant été trouvé et corrigé qu'à la sortie du firmware 14.0.0 de la console, soit plus de 5 ans après les premiers rapports. % https://gist.githubusercontent.com/plutooo/2aadbd4a718e269df474079dd2e584fb/raw/7b3af77b5202366c8934c88ef251f1e905967040/gistfile1.txt
On pourrait aussi citer une vulnérabilité exploitée dans la pile IPV6 du noyau FreeBSD de la console Playstation 4 de Sony, profitant d'une situation de concurrence critique pour déclecher un Use-After-Free et compromettant le système d'exploitation. Cette faille présente sur tous les firmwares de la console depuis son lancement en 2013 a été découverte en 2018 puis divulguée et patchée en 2020, soit 7 ans après sa mise sur le marché.

Certains débuggers (notamment \texttt{rr}~\cite{mozRR}) ont implémenté une fonctionnalité "\emph{record and replay}" (enregistre et rejoue), permettant de capturer une trace du programme inspecté, puis de rejouer dynamiquement cette même trace à la demande. Cette fonctionnalité résoud le problème de la reproductibilité des comportement anormaux des programmes, et permet de surcrois de revenir à un état précédent de l'exécution lors d'une session de débuggage, ce qui est impossible avec les débuggers classiques. Certains émulateurs tels que Xen ou Qemu proposent des fonctionnalités "record and replay" sur les machines virtualisées. Malheureusement, les fonctionnalités "record and replay" pour des programmes sur plusieurs coeurs sont actuellement extrêmement lents, et profiteraient grandement d'implémentation matérielles si elles venaient à exister \cite{mozRR}.

De nombreux travaux ont été menés afin de détecter les situations de concurrence critique, par exemple par analyse statique~\cite{racerX}. D'autres travaux ont développés des méthodes plus particulières permettant de découvrir des situations de concurrence critique liées aux interruptions matérielles~\cite{sdracer}. Parallèlement, dans le monde de la preuve formelle, on pourrait citer les travaux ayant abouti à la logique de séparation~\cite{separationlogic}.

		\subsection{Software}

			\subsubsection{Capture de l'état d'exécution}

			\subsubsection{Changement de droits}

				Espace d'adressage, niveau de privilèges

		\subsection{Failles de sécurités associées}
			%https://google.github.io/security-research/pocs/linux/bleedingtooth/writeup.html#achieving-rip-control
			%https://google.github.io/security-research/pocs/linux/cve-2021-22555/writeup.html
			%https://github.com/Bonfee/CVE-2022-0995
			CVE historiques ? :D

			%https://pointer-authentication.github.io/

		\subsection{Ordonnancement}

			\subsubsection{Partage équitable du CPU}

			\subsubsection{Respect des contraintes de temps}

	\section{Preuve de code}

		\subsection{Vérification automatique d'une preuve}

			\subsubsection{Qu'est ce qu'une preuve ?}

				\paragraph{Axiomes}
				\paragraph{Hypothèses}
				\paragraph{Raisonnement}

			\subsubsection{Exemple de Coq}

			\subsubsection{Stratégie de conduite / vérification de preuve}

				\paragraph{Preuve directe}
				\paragraph{Preuve par raffinement}

		\subsection{Preuve de programme}

			\subsubsection{Raisonner sur un programme impératif}

				\paragraph{preconditions}

				\paragraph{règles de transition} (sémantique opérationnelle)

				\paragraph{postconditions} (Hoare, logique de séparation)

			\subsubsection{Langage}

				\paragraph{Représentation du programme} (deep/shallow)

				\paragraph{Monade}

		\subsection{Illustration système}

			\subsubsection{SeL4}
			\subsubsection{CertikOS}
			\subsubsection{Pip}
