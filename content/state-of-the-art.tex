\chapter{État de l'art (20-30 pages)}

	Ce chapitre a pour intention de définir et préciser les différentes notions nécessaires à la lecture des travaux de thèses, ainsi que de définir le contexte scientifique du travail. Il portera, dans une première section, sur les détails des différents transferts de flot d'exécution dans les systèmes modernes, ainsi que les changements d'états inhérents à ces transferts de flot d'exécution. Cette section abordera ensuite les problèmes de sécurité liés au transfert de flot d'exécution, ainsi que les techniques de mitigation de ces problèmes. Cette section terminera sur les problématiques temps réel touchant au transfert de flot d'exécution.
	La seconde section de ce chapitre fera un état des lieux de la preuve de programme. Elle commencera par discuter de ce qu'est une preuve et de leur vérificaton automatique, ainsi que des stratégies de conduite de preuve. Cette section continuera sur la preuve de programme, en particulier comment raisonner sur un programme impératif. Elle abordera aussi les notions de représentation du langage. Enfin, elle terminera sur les exemples de systèmes vérifiés formellement.

	\section{Transfert de flôt d'exécution}

		Cette section va détailler les différents transferts de flot d'exécution mis à disposition dans les cpus modernes.
		Dans cette section, nous détaillerons les transferts de flot d'exécution qui impliquent une reconfiguration explicite de l'état de la machine ayant un impact sur les droits d'accès aux ressources. Les appels d'une fonction d'un programme vers une autre fonction ne seront pas considérés dans cette section, même s'ils pourraient être considérés comme un transfert de flôt d'exécution.


		\subsection{Hardware}

			\subsubsection{Appels explicites}
			Les transferts les plus courants sont les transferts de flot d'exécution explicites, c'est-à-dire dont la cible est explicitement fournie lors de l’appel, ou clairement établie dans la documentation.

Par exemple, dans Linux, un processus peut demander l’ouverture d’un fichier avec l’appel système open(). Cet appel transfère le flot d’exécution d’un processus non privilégié vers le noyau Linux disposant du plus haut niveau de privilèges. Les fonctions appelables par des transferts explicites servent d’interface entre des logiciels disposant de droits distincts.



Ce type de transfert de flôt d'exécution, d'apparence assez anodine, est pourtant l'objet d'attaques multiples, dont le but est de faire dévier l'exécution (de préférence en mode privilégié) vers du code choisi par l'attaquant. Pour y arriver, un attaquant doit exploiter une vulnérabilité dans une portion de code, qui lui donnera le contrôle d'une zone de mémoire d'intérêt (la pile, le tas, ou même le code). Une fois qu'il contrôle cette zone mémoire, il lui suffit d'écrire un \emph{shellcode}, et d'exploiter une vulnérabilité dans du code privilégié pour que l'exécution du \texttt{return} de la fonction compromise saute dans le shellcode. L'attaquant gagne à ce moment le contrôle de la machine.

Commence alors un jeu du chat et de la souris pour essayer de mitiger l'impact de ces vulnérabilités. Pour compliquer la vie de l'attaquant, et qu'il lui soit plus difficile d'exécuter son shellcode, de nombreuses stratégies ont été entreprises par les fabriquant de matériels ainsi que par les développeurs de systèmes d'exploitation. 

\paragraph{Canaries}
Une première statégie est l'ajout de \emph{canary} qui visent à détecter les corruptions mémoires. Les canaries sont des valeurs écrites dans la pile ou le tas et qui sont générées aléatoirement à chaque exécution. Lors de la sortie de la frame protégée par le canary, le code vérifie que la valeur du canary correspond bien à celle qui avait été écrite initialement ; si ce n'est pas le cas, c'est qu'une corruption mémoire a eu lieu et une faute est levée.

Une des techniques permettant de vaincre les canaries est de lire la valeur initiale du canary avant de corrompre la mémoire. En effet, la canary \textbf{reste la même pour l'intégralité de l'exécution}. Une fois cette valeur récupérée, il suffit de corrompre la mémoire en réécrivant cette valeur au bon endroit pour échapper à la détection. De plus, si l'exploitation de la vulnérabilité permet de corrompre la mémoire de manière fine, il suffit d'éviter d'écrire sur la canary.

\paragraph{Droits fins pour les zones mémoires}
Une autre stratégie a été de définir des droits fins concernant l'accès aux différentes zones mémoires de l'espace d'adressage des processus. Le mécanisme de mémoire virtuelle permet de définir des droits d'accès propres à chaque page mémoire configurée (lecture, écriture, éxecution, accessible en mode non priviligié). Par exemple, les pages mémoire contenant du code sont typiquement configurées pour des accès en lecture et exécution, alors que les pages contenant des données (pour la pile, le tas, les sections de données d'un binaire) sont configurées pour des accès en lecture/écriture.

Cette stratégie de défense empêche un attaquant d'exploiter une vulnérabilité pour écrire un shellcode code dans la mémoire si on considère que chaque page de mémoire est soit exécutable, soit accessible en écriture. Cependant, il existe des cas d'usage légitimes qui violent cette contrainte, par exemple lors de compilation à la volée (ou JIT, pour Just-In-Time). Fatalement, de tels logiciels sont devenus la cible privilégiée des attaquants, on pourra par exemple citer Webkit.% https://github.com/saelo/cve-2018-4233
Heureusement, il est peu probable que de tels logiciels aient besoin de s'exécuter en mode privilégié. 

Pour affaiblir ce vecteur d'attaque, cette stratégie de défense est renforcée par des mécanismes de sécurité supplémentaires tels que le \emph{Supervisor Mode Access Prevention} (SMAP) et le \emph{Supervisor Mode Execution Prevention} (SMEP). SMAP permet au processeur de lever une faute lorsque qu'il exécute du code privilégié et qu'il essaie d'accéder (en lecture ou en écriture) à des données présentes dans l'espace utilisateur. SMEP permet en complément de lever une faute lorsque le processeur essaie d'exécuter du code dans l'espace utilisateur alors qu'il se trouve dans un mode d'exécution privilégié.

Ces mécanismes permettent d'isoler le code privilégié de potentiels shellcodes écrit en espace utilisateur. Ainsi, pour compromettre intégralement un système, l'attaquant doit à présent exploiter une vulnérabilité dans le code privilégié, ayant à sa disposition des pages mémoire soit accessibles en écriture soit exécutables et qui, de surcrois, ne font pas partie de l'espace utilisateur.
Nait alors une nouvelle technique d'exploitation de vulnérabilité. 

\paragraph{Return Oriented Programming}
Le ROP (pour \emph{Return Oriented Programming}) consiste à attaquer du code vulnérable en n'utilisant que le code déjà accessible dans l'environnement d'origine, mais en exécutant des portions arbitraires de celui-ci. L'attaque consiste à repérer des \emph{gadgets} : de brèves portions de code ayant un effet spécifique sur la mémoire ou les registres, suivi d'une instruction \texttt{return}. Pour l'attaquant, il suffit de dévier le flot d'exécution sur l'un de ces gadgets et de manipuler la mémoire, de manière à ce que l'exécution du gadget entraine l'exécution du suivant. L'attaquant parvient au final à exécuter son shellcode constitué d'une succession de gadgets, contournant les mécanismes de sécurité mentionnés dans le paragraphe précédent.\\

Plusieurs contre-mesures ont émergé pour rendre plus difficile le ROP.

\paragraph{Address Space Layout Randomization}
L'ASLR (pour \emph{Address Space Layout Randomization}) rend imprédictible l'adresse des différentes zones de mémoire au sein d'un espace d'adressage virtuel. Les adresses du binaire, de la pile, du tas, des librairies, du noyau, etc. sont rendus aléatoires à chaque nouvelle exécution. L'ASLR est un de ce fait un frein considérable au développement d'un shellcode en ROP, puisqu'il est impossible de prédire où se situeront les gadgets lors de la prochaine exécution.

L'ASLR n'est cependant pas parfait. Les adresses des zones mémoire restantes peuvent être révélées par des pointeurs dans les zones mémoires controlées par l'attaquant, %https://google.github.io/security-research/pocs/linux/cve-2021-22555/writeup.html#bypassing-kaslrsmep and %https://google.github.io/security-research/pocs/linux/bleedingtooth/writeup.html#leaking-the-memory-layout
ou grâce à des attaques micro-architecturales % Prefetch Side-Channel Attacks: Bypassing SMAP and Kernel ASLR. In: CCS’16 (2016) && Practical Timing Side Channel Attacks against Kernel Space ASLR. In: S&P’13 (2013)

\paragraph{Vérification de l'intégrité du flôt d'exécution}

Une autre approche permettant de réduire la marge de manoeuvre de l'attaquant et de vérifier que le flot d'exécution est conforme à celui attendu. À chaque appel et à chaque retour de fonction, le processeur vérifie si la cible du saut est valide. Plusieurs implémentations existent, notamment des implémentations métarielles au sein des processeurs, mais aussi certaines implémentation logicielles notamment provenant de compilateurs. Windows, macOS, Android, iOS utilisent déjà un mécanisme de vérification du flot d'exécution.
% https://community.arm.com/arm-community-blogs/b/architectures-and-processors-blog/posts/armv8-1-m-pointer-authentication-and-branch-target-identification-extension
% https://www.intel.com/content/dam/develop/external/us/en/documents/catc17-introduction-intel-cet-844137.pdf
% https://clang.llvm.org/docs/ControlFlowIntegrity.html


\paragraph{eXecute Only Memory}
Le XOM (pour \emph{eXecute Only Memory}), est une fonctionnalité de certain processeurs permettant de déclencher une faute lorsque qu'un accès en lecture est fait sur les pages mémoires configurées comme étant exécutables. Avant cette fonctionnalité, aucune distinction n'était faite entre le processus de récupération des instructions par le processeur et la lecture de données par l'utilisateur. Cette fonctionnalité rend considérablement pour difficile la recherche de gadgets, puisqu'il est impossible pour l'attaquant de lire le code qu'il souhaite compromettre directement sur la cible.
On pourrait cependant argumenter que cette fonctionnalité relève de la sécurité par l'obscurité, et qu'elle n'est pas réellement efficace.

\paragraph{\blockquote{Mieux vaut prévenir que guérir}}

Ces contre-mesures, sans cesse contournées par de nouvelles méthodes d'attaque, supposent qu'il existera toujours des vulnérabilités dans le logiciel comme dans le matériel et tentent donc de limiter au maximum leur impact sur les systèmes affectés. Une toute autre classe de mesures essaie de régler le problème en s'attaquant à l'existence même des vulnérabilités, plutôt que d'essayer minimiser leurs conséquences.

On pourrait citer les méthodes d’analyse statique, les méthodes d’exécution symbolique, de fuzzing, et plus particulièrement le langage Rust conçu pour éradiquer ces vulnérabilités par conception. Par ailleurs, des travaux ont été entamés pour prouver formellement les fonctionnalités de Rust.


			\subsubsection{Fautes}

Les différentes formes de fautes logicielles constituent aussi une forme de transfert de flot d'exécution avec élévation de privilèges. Les logiciels sont susceptibles de déclencher des fautes logicielles de différentes façons, par exemple :
\begin{itemize}
  \item décodage impossible de la prochaine instruction ;
  \item demande d'exécution d'une instruction impossible (division par zéro...) ; 
  \item demande d'accès à une adresse mémoire protégée, résultat de l'activité d'une MMU ;  
  \item demande d'exécution d'une instruction privilégiée en mode non-privilégié.
\end{itemize}
Dans ces différentes situations il s'agit de transferts implicites depuis le logiciel en faute vers une fonction d'un logiciel en charge du traitement de cette faute. Les différentes fonctions de gestion des fautes sont généralement définies par des éléments de configuration du matériel, et, le plus souvent, par l'intermédiaire d'une table (ou vecteur) dont le nom change d'une architecture de microprocesseur à l'autre. Ce vecteur précise généralement le niveau d'élévation de privilèges associé à l'exécution de la fonction de traitement de la faute. Sur les architectures Intel cette table est appelée \emph{IDT} (pour \emph{Interrupt Descriptor Table}).

\subsubsection{Interruptions matérielles}
Les interruptions matérielles sont des transferts non explicites à priori non contrôlés par le code non privilégié. Elles sont déclenchées par le matériel, signalant un événement important à traiter, tel que l'arrivée d'un paquet réseau par exemple. Les fonctions de traitement des interruptions matérielles ainsi que leur niveau de privilèges sont aussi définis dans l'\emph{IDT}.

Puisque les fautes et interruptions déclenchent un changement de privilèges, elles sont un vecteur d'attaque supplémentaire d'intérêt pour un attaquant cherchant à s'octroyer de nouveaux droits. En effet, les mêmes types de failles peuvent résider dans les routines de gestion de ces portions de logiciel. De plus, les interruptions et fautes brisent le flot d'exécution et modifient potentiellement l'environnement d'exécution du code interrompu. Cela les rends d'autant plus susceptibles de contenir des vulnérabilités, qui tombent alors dans la catégorie des vulnérabilités de \emph{concurrence critique}.

Même en ayant pleinement conscience des différentes interactions et dépendances entre les différents composants d'un système, les vulnérabilités de concurrence critique sont \textbf{notoirement difficiles à cerner}, principalement à cause d'un phénomène d'explosion combinatoire. Il peut s'avérer difficile de détecter une telle vulnérabilité par les tests, puisqu'ils sont souvent effectués dans des environnement très controlés où les mêmes conditions d'exécution sont artificiellement répétées, occultant d'autres fils d'exécution possibles. Malgré cela, si le développeur parvient à exhiber un fil d'exécution contenant un comportement anormal, il peut alors être délicat de reproduire le fil d'exécution ayant conduit à ce comportement. En effet, le fil d'exécution peut etre le résultat de nombreuses interactions - parfois non-déterministes - du programme avec son environnement. De plus, attacher un debuggueur tel que \texttt{gdb} peut modifier subtilement ces interactions, de manière telle qu'il soit impossible d'exhiber à nouveau le comportement anormal : on parle alors d'Heisenbug. Pour illustrer la difficulté à cerner cette catégorie de bugs, on pourrait citer un problème d'incohérence de cache dans le noyau de système d'exploitation de la Nintendo Switch après une interruption matérielle ayant mené à un changement de coeur. Les effets de ce bug avaient été observés dès la sortie de la console ; il n'a cependant été trouvé et corrigé qu'à la sortie du firmware 14.0.0 de la console, soit plus de 5 ans après les premiers rapports. % https://gist.githubusercontent.com/plutooo/2aadbd4a718e269df474079dd2e584fb/raw/7b3af77b5202366c8934c88ef251f1e905967040/gistfile1.txt
On pourrait aussi citer une vulnérabilité exploitée dans la pile IPV6 du noyau FreeBSD de la console Playstation 4 de Sony, profitant d'une situation de concurrence critique pour déclecher un Use-After-Free et compromettant le système d'exploitation. Cette faille présente sur tous les firmwares de la console depuis son lancement en 2013 a été découverte en 2018 puis divulguée et patchée en 2020, soit 7 ans après sa mise sur le marché.

Certains débuggers (notamment \texttt{rr}~\cite{mozRR}) ont implémenté une fonctionnalité "\emph{record and replay}" (enregistre et rejoue), permettant de capturer une trace du programme inspecté, puis de rejouer dynamiquement cette même trace à la demande. Cette fonctionnalité résoud le problème de la reproductibilité des comportement anormaux des programmes, et permet de surcrois de revenir à un état précédent de l'exécution lors d'une session de débuggage, ce qui est impossible avec les débuggers classiques. Certains émulateurs tels que Xen ou Qemu proposent des fonctionnalités "record and replay" sur les machines virtualisées. Malheureusement, les fonctionnalités "record and replay" pour des programmes sur plusieurs coeurs sont actuellement extrêmement lents, et profiteraient grandement d'implémentation matérielles si elles venaient à exister \cite{mozRR}.

De nombreux travaux ont été menés afin de détecter les situations de concurrence critique, par exemple par analyse statique~\cite{racerX}. D'autres travaux ont développés des méthodes plus particulières permettant de découvrir des situations de concurrence critique liées aux interruptions matérielles~\cite{sdracer}. Parallèlement, dans le monde de la preuve formelle, on pourrait citer les travaux ayant abouti à la logique de séparation~\cite{separationlogic}.

		\subsection{Software}

			\subsubsection{Changement de droits}

Sur l'architecture Intel x86, les différents transferts de flot d'exécution peuvent s'opérer par le biais de différentes instructions et événements matériels. Néanmoins, lorsqu'un changement de droits est requis lors d'un transfert, les différents chemins sont régis par un ensemble de mécanismes de contrôle relativement homogènes.

\paragraph{Changement de droits sous x86}
\label{ring}

Les privilèges attribués au code s'exécutant actuellement sur la machine sont ceux du \emph{segment} chargé dans le registre \texttt{CS} (pour \emph{code segment}). Les segments sont définis dans la \emph{GDT} (pour \emph{Global Descriptor Table}) à l'initialisation de la machine. La \emph{GDT} est une table globale spécifiée par Intel, dont l'adresse est accessible par un registre dédié. Dans cette table par exemple, Linux se contente de définir deux segments de code. Un premier segment associé au niveau de privilèges maximum du microprocesseur, nommé par Intel \emph{ring 0}, utilisé pour le code responsable du système ; et un second segment non-privilégié, associé au niveau de privilèges \emph{ring 3}, pour le reste du code. 

Contrairement au code s'exécutant avec le segment privilégié, le code s'exécutant sans privilège ne peut pas changer de segment à sa guise. Des mécanismes de contrôle du processeur déclenchent une faute si du code non-privilégié essaie de modifier son segment de code. Pour y parvenir, il est possible d'utiliser les \emph{gates}, qui sont des tremplins définis dans les tables globales du système (comme l'\emph{IDT} ou la \emph{GDT}), permettant au code non privilégié d'appeler une fonction prédéfinie qui s'exécute avec d'autres droits.

Lorsqu'un changement de segment déclenche un changement de niveau de privilèges, le processeur change de pile. Ce changement de pile permet d'éviter aux routines privilégiées les échecs dus à un manque de place sur la pile, ainsi qu'à les prémunir d'éventuelles interférences avec les procédures non privilégiées~\cite{intel_stack_switch}. 
Une pile doit être définie par niveau de privilèges (\emph{ring}) utilisé par le système ; leurs adresses doivent être renseignées dans une structure appelée \emph{TSS} (pour \emph{Task State Segment}). Cette structure est initialisée conjointement avec la \emph{GDT} qui contient son descripteur. Un registre dédié indique au processeur la position de ce descripteur dans la \emph{GDT}.

\paragraph{Appels systèmes sur x86}

Afin d'obtenir un transfert de flot d'exécution avec élévation de privilèges, le logiciel appelant non-privilégié peut exécuter des instructions dédiés aux différentes \emph{gates} des tables globales. Tout d'abord, l'instruction \texttt{int} permet d'appeler les \emph{gates} situées dans l'\emph{IDT}. Ces \emph{gates} sont soit des \emph{interrupt gates}, des \emph{trap gates} ou des \emph{task gates}~\cite{intel_idt_gates}. \texttt{int} s'accompagne d'un argument correspondant à l'index de la \emph{gate} ciblée dans l'\emph{IDT}. Le code ainsi appelé sera exécuté avec le niveau de privilèges spécifié par le segment de code indiqué dans la gate (et chargé dans le registre \texttt{CS}).

L'instruction \texttt{callf} permet d'utiliser les \emph{gates} situées dans la \emph{GDT}. Ces gates sont soit des \emph{call gates} ou des \emph{task gates}. Ces gates permettent de copier un nombre fixé d'arguments depuis la pile de l'appelant dans la pile du code privilégié à l'appel de l'instruction \texttt{callf}. Le nombre d'arguments à copier est renseigné dans la \emph{gate} ciblée par l'instruction. Là aussi, l'élevation de privilèges est spécifiée par le segment de code indiqué dans la gate et chargé dans \texttt{CS} lors de l'appel.

La troisième manière de déclencher une élévation de privilèges est l'instruction \texttt{sysenter}. Cette 
instruction ne sollicite aucune \emph{gate} : à la place, elle utilise les \emph{MSR} (pour \emph{model-specific registers}), qui sont des registres de contrôle du processeur. Ces \emph{MSR} sont manipulables grâce aux instructions \texttt{wrmsr} et \texttt{rdmsr}, qui sont des instructions privilégiées et qui permettent d'écrire et de lire dans ces registres respectivement. Un appel à \texttt{sysenter} utilise les MSR \texttt{0x174}, \texttt{0x175} et \texttt{0x176} pour charger \texttt{CS} \texttt{EIP} \texttt{SS} \texttt{ESP}. Le système doit donc avoir initialisé ces registres avant l'utilisation de \texttt{sysenter}. De plus, \texttt{sysenter} ne sauvegarde pas l'adresse de retour ni l'adresse de la pile lors d'un appel, qui doivent être placés dans les registres \texttt{ECX} et \texttt{EDX} au moment de l'appel à \texttt{sysexit} pour retourner dans le code appelant.

\paragraph{Interruptions et fautes sur x86}

Les interruptions liées au matériel sur l'architecture x86 étaient autrefois gérées par un coprocesseur (le PIC 8259 \emph{pour Programmable Interrupt Controller} ou plus récemment, l'APIC pour \emph{Advanced Programmable Interrupt Controller}). Ce coprocesseur est maintenant intégré au processeur, mais nous continuerons de parler de coprocesseur pour honorer l'histoire. Ce coprocesseur utilise les \emph{gates} situées dans l'IDT de la même manière que l'instruction \texttt{int}. Il est possible de configurer ce coprocesseur
pour qu'il utilise une certaine plage de niveaux d'interruption, ou pour qu'il masque temporairement la venue de nouvelles interruptions. Les fautes utilisent elles aussi l'\emph{IDT}, et utilisent les trente-deux premières \emph{gates} de la table, en fonction de la faute à déclencher. Les fautes et interruptions déclenchées par le processeur ou le coprocesseur ont toujours le droit d'utiliser les \emph{gates}, peu importe le niveau de privilèges du code s'exécutant au moment de l'interruption.

\paragraph{Fonctionnement de la \emph{MMU} sur l'architecture Intel 32 bits}

Sur l'architecture Intel x86, mais aussi sur toutes les autres architectures supportant une \emph{MMU} (pour \emph{Memory Management Unit}), il est possible d'associer des droits d'accès spécifiques à chaque pages de mémoire configurée dans l'espace d'adressage virtuel.

Le concept de traduction d'adresse virtuelle vers l'adresse réelle est le suivant. Les bits de poids forts de l'adresse virtuelle servent à traverser les tables de la MMU (sur l'architecture Intel x86, le \emph{Page Directory} et les \emph{Page Tables}). Les bits de poids faible correspondent à l'emplacement de l'adresse désirée dans la page réelle obtenue après traduction (souvent appelé \emph{offset}).

En particulier, sur Intel x86 et en mode de pagination 32 bits pour des pages de 4 Kio, les espaces d'adressage sont configurés par une structure de données arborescente de pages de 4Kio. Cette structure de données a deux étages : la racine appelée PD pour \emph{Page Directory}, et les feuilles appelées PT (pour \emph{Page Tables}). Le développeur renseigne l'adresse du Page Directory à utiliser dans le registre \texttt{CR3} du processeur ; cette adresse est alignée sur 4Kio, les 12 bits de poids faibles (11-0) sont ignorés ou sont réservés pour un autre usage.

Plus précisement, le \emph{Page Directory} est constitué de 1024 entrées de 32 bits appelées les \emph{PDE} (pour \emph{Page Table Entries}). Les 20 bits de poids fort (31-12) de ces entrées déterminent l'adresse de la \emph{Page Table} à utiliser, alignée sur 4Kio. Les \emph{Page Tables} sont aussi constituée de 1024 entrées de 32 bits appelées \emph{PTE} (pour \emph{Page Table Entries}). De la même manière, les 20 bits de poids forts (31-12) déterminent l'adresse de la page de mémoire réelle, alignée sur 4Kio. (Il est aussi possible de configurer des pages de 4Mio plutot que des pages de 4Kio en modifiants certains bits de controle des \emph{PDE}.)

Lors de la traduction d'une adresse virtuelle, les 10 bits de poids forts de l'adresse virtuelle (31-22) déterminent le numéro de \emph{PDE} à utiliser, les bits (21-12) déterminent le numéro de \emph{PTE}, et les 12 bits de poids faible restants (11-0) déterminent l'\emph{offset} de l'adresse cible dans la page réelle.~\cite{intel_32bits_paging}

\paragraph{Contrôle d'accès par la MMU sur Intel x86}
Dans le mode de pagination 32 bits d'Intel, les droits associés à chaque page sont présents dans les \emph{PTE}, dans les 12 bits de poids faible. Le bit 1 (\texttt{R/W}) permet d'empêcher les accès en écriture sur la page. Le bit 2 (\texttt{U/S}) permet d'empêcher n'importe quel accès utilisateur à la page - en lecture ou en écriture. Le niveau de privilège de l'accès dépend du \emph{CPL} (pour \emph{Current Privilege Level}) de l'instruction courante, souvent déterminée par le segment de code actuel.

Cependant, d'autres fonctionnalités de contrôle d'accès globaux existent.
Le bit \emph{SMAP} (pour \emph{Supervisor Mode Access Protection} présent dans le registre CR4 permet d'empêcher du code privilégié d'accéder aux pages mémoire annoncées comme étant des pages mémoire utilisateur (bit \texttt{U/S}).

Les architectures x86 (et x64) présentent dans le détail, une grande diversité de modalités de transferts de flot d'exécution, dont cette section a fait une synthèse incomplète. Cette pluralité de modalités de transfert de flot de contrôle est une source de failles de sécurité importante, tant les éléments de configurations sont nombreux et sujet à des paramétrages contradictoires. Le proto-noyau Pip a proposé une méthodologie nouvelle pour produire la preuve de bonne configuration des MMU, garantissant la propriété d'isolation des logiciels. La section suivante présente cette stratégie de conduite de preuve, puis la section suivante présente notre contribution pour adapter cette stratégie à la preuve de sécurité lors des transferts
de flot d'exécution avec élévation de privilèges.

				Espace d'adressage, niveau de privilèges

			\subsubsection{Capture de l'état d'exécution}

Un transfert de flot d'exécution implique l'existence de deux entités distinctes présentes à l'intérieur du système. Nous allons ici développer les morceaux de logiciels nécessaires permettant de reprendre l'exécution d'une entité.


Nous avons vu dans la section précédente que le transfert de flôt d'exécution peut survenir à l'insu total de l'entité interrompue. De ce fait, l'entité est peut être en plein travail, et ne s'est pas nécessairement préparée à ce transfert qui requisitionnerait instantanément une partie des ressources disponibles. C'est pourquoi il incombe au système d'exploitation de faire le nécessaire pour que le transfert soit transparent pour l'entité interrompue. L'entité doit pouvoir reprendre son travail comme si le transfert n'avait jamais eu lieu : le système d'exploitation doit garantir son \emph{contexte d'exécution}. 

\paragraph{Le contexte d'exécution}

Le contexte d'exécution doit alors contenir tout ce qui est susceptible d'être modifié ultérieurement par l'autre entité ou lors du transfert de flot d'exécution. Au minimum, le pointeur d'instruction est préservé. Lors d'un changement de droits sous x86, le processeur opère un changement de pile. 


De quoi est constitué ce contexte d'exécution ? À priori cela concerne au moins certains registres du processeur, la mémoire accessible par l'entité, 

Se pose alors la question de ce qu'est l'état d'un programme. Sur un système donné et un programme donné, quel est l'ensemble des informations qu'il est nécessaire de conserver pour reproduire à l'identique le comportement original du programme ?




		\subsection{Failles de sécurités associées}
			%https://google.github.io/security-research/pocs/linux/bleedingtooth/writeup.html#achieving-rip-control
			%https://google.github.io/security-research/pocs/linux/cve-2021-22555/writeup.html
			%https://github.com/Bonfee/CVE-2022-0995
			CVE historiques ? :D

			%https://pointer-authentication.github.io/

		\subsection{Ordonnancement}

			\subsubsection{Partage équitable du CPU}

			\subsubsection{Respect des contraintes de temps}

	\section{Preuve de code}

		\subsection{Vérification automatique d'une preuve}

			\subsubsection{Qu'est ce qu'une preuve ?}

				\paragraph{Axiomes}
				\paragraph{Hypothèses}
				\paragraph{Raisonnement}

			\subsubsection{Exemple de Coq}

			\subsubsection{Stratégie de conduite / vérification de preuve}

				\paragraph{Preuve directe}
				\paragraph{Preuve par raffinement}

		\subsection{Preuve de programme}

			\subsubsection{Raisonner sur un programme impératif}

				\paragraph{preconditions}

				\paragraph{règles de transition} (sémantique opérationnelle)

				\paragraph{postconditions} (Hoare, logique de séparation)

			\subsubsection{Langage}

				\paragraph{Représentation du programme} (deep/shallow)

				\paragraph{Monade}

		\subsection{Illustration système}

			\subsubsection{SeL4}
			\subsubsection{CertikOS}
			\subsubsection{Pip}
